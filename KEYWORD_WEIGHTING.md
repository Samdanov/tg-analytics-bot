# Взвешивание ключевых слов по позиции

## Что изменилось

Добавлена система **взвешивания ключевых слов по позиции** в списке. Теперь первые ключевые слова (главная тема канала) имеют больший вес при поиске похожих каналов, чем последние (контекст).

## Проблема, которую решает

### До изменений
```python
Канал про дрессировку собак:
keywords = ["собака", "дрессировка", "питомец", "команда", "воспитание"]

При сравнении все ключи имели равный вес:
- "собака" (главная тема) = вес 1.0
- "воспитание" (контекст) = вес 1.0

Проблема: Если совпадает только "воспитание", канал получает такой же score,
как если бы совпала "собака" (хотя это разные уровни важности!)
```

### После изменений
```python
Канал про дрессировку собак:
keywords = ["собака", "дрессировка", "питомец", "команда", "воспитание"]

Автоматическое взвешивание по позиции:
- "собака" (1-й ключ) → вес 1.00  ← самый важный!
- "дрессировка" (2-й) → вес 0.83
- "питомец" (3-й)     → вес 0.65
- "команда" (4-й)     → вес 0.48
- "воспитание" (5-й)  → вес 0.30  ← менее важный

Теперь: Совпадение по "собака" даст в 3.3 раза больший вклад в similarity,
чем совпадение по "воспитание"
```

## Как это работает

### Формула взвешивания

**Linear decay** с минимальным весом 0.3:

```python
weight = 1.0 - (position / (total - 1)) * 0.7

где:
- position = индекс ключевого слова (0, 1, 2, ...)
- total = общее количество ключевых слов
- min_weight = 0.3 (минимальный вес для последних ключей)
```

### Примеры

**Пример 1: 5 ключевых слов**
```
["python", "django", "api", "backend", "разработка"]
→
python:      1.00  (главная тема)
django:      0.83
api:         0.65
backend:     0.48
разработка:  0.30  (контекст)
```

**Пример 2: 10 ключевых слов**
```
["игра", "steam", "геймдев", "инди", "разработка", "unity", "релиз", "киберспорт", "стратегия", "симулятор"]
→
игра:        1.00
steam:       0.92
геймдев:     0.84
инди:        0.77
разработка:  0.69
unity:       0.61
релиз:       0.54
киберспорт:  0.46
стратегия:   0.38
симулятор:   0.30
```

**Пример 3: 3 ключевых слова**
```
["кино", "трейлер", "премьера"]
→
кино:      1.00
трейлер:   0.65
премьера:  0.30
```

## Влияние на similarity score

### Пример 1: Совпадение по главному ключу

```
Канал А (дрессировка):
  ["собака": 1.00, "дрессировка": 0.83, "питомец": 0.65]

Канал Б (уход за собаками):
  ["собака": 1.00, "уход": 0.83, "кормление": 0.65]

Совпадение: "собака" (1.00 × 1.00 = 1.00)
→ Высокий similarity score! ✅
```

### Пример 2: Совпадение по второстепенному ключу

```
Канал А (дрессировка):
  ["собака": 1.00, "дрессировка": 0.83, "питомец": 0.65]

Канал В (ветеринария):
  ["ветеринар": 1.00, "лечение": 0.83, "собака": 0.30]

Совпадение: "собака" (1.00 × 0.30 = 0.30)
→ Низкий similarity score (каналы про разное) ✅
```

### Пример 3: Несколько совпадений

```
Канал А (Python):
  ["python": 1.00, "django": 0.83, "api": 0.65, "backend": 0.48]

Канал Б (Django):
  ["django": 1.00, "python": 0.83, "api": 0.65, "orm": 0.48]

Совпадения:
  - "python": 1.00 × 0.83 = 0.83
  - "django": 0.83 × 1.00 = 0.83
  - "api":    0.65 × 0.65 = 0.42
  Total: 2.08

→ Очень высокий similarity score! ✅✅
```

## Технические детали

### Файлы с изменениями

1. **`app/services/similarity_engine/shared.py`**
   - Добавлена функция `calculate_position_weights()`
   - Вычисляет веса на основе позиции

2. **`app/services/similarity_engine/engine.py`**
   - Обновлен метод `_calculate_within_category()`
   - Использует weighted TF вместо обычного TF

3. **`app/services/similarity_engine/engine_single.py`**
   - Обновлена функция `calculate_similarity_for_channel()`
   - Применяет веса для single channel анализа

### Формула TF-IDF с весами

**До:**
```python
TF = count(term)  # просто частота слова
TF-IDF = TF × IDF
```

**После:**
```python
TF = Σ position_weight(term)  # взвешенная частота
TF-IDF = TF × IDF
```

Где `position_weight` определяется позицией ключевого слова в списке.

## Преимущества

✅ **Учитывает важность ключевых слов**
   - Первые ключи (главная тема) важнее последних (контекст)

✅ **Более точная выдача похожих каналов**
   - Совпадение по главным темам = высокий score
   - Совпадение только по контексту = низкий score

✅ **Не требует изменения LLM промпта**
   - LLM уже генерирует keywords в порядке важности
   - Мы просто используем эту информацию

✅ **Обратная совместимость**
   - Работает с существующими данными в БД
   - Не требует переанализа каналов

✅ **Гибкость**
   - Можно настроить минимальный вес (default: 0.3)
   - Легко изменить стратегию взвешивания

## Как использовать

### Автоматически (рекомендуется)

Система **автоматически применяется** при:
1. Batch-расчете similarity: `python -m app.services.similarity_engine.cli batch`
2. Single channel анализе: `python -m app.services.similarity_engine.cli single <ID>`
3. Анализе канала через бота

Никаких дополнительных действий не требуется!

### Пересчет для существующих каналов

Чтобы применить новую систему взвешивания к существующим каналам:

```bash
cd /home/alex/apps/tg-analytics-bot
source venv/bin/activate

# Пересчитать для всех каналов (медленно, 10-60 мин)
python3 -m app.services.similarity_engine.cli batch

# ИЛИ для одного канала (быстро, 10-30 сек)
python3 -m app.services.similarity_engine.cli single <CHANNEL_ID>
```

## Ожидаемый эффект

### Качество выдачи

**До:** Каналы могли считаться похожими из-за совпадения по второстепенным ключевым словам.

**После:** Каналы с совпадением по **главной теме** будут выше в выдаче, чем каналы с совпадением только по контексту.

### Примеры улучшения

**Канал про Python разработку:**
- **Улучшение:** Другие Python каналы будут выше в топе
- **Почему:** Совпадение по главному ключу "python" даст высокий score

**Канал про дрессировку собак:**
- **Улучшение:** Каналы про собак будут выше ветеринарных каналов
- **Почему:** "собака" на 1-м месте у обоих vs "собака" на 5-м месте у вет. канала

**Канал про трейлеры и кино:**
- **Улучшение:** Netflix/кино каналы будут выше новостных
- **Почему:** Совпадение "кино", "трейлер" (главные ключи) vs "новости" (контекст)

## Настройка (для разработчиков)

### Изменение минимального веса

В `shared.py`:
```python
def calculate_position_weights(tokens: List[str], min_weight: float = 0.3):
    # Изменить min_weight:
    # 0.3 (default) = последние ключи имеют 30% веса
    # 0.5 = более мягкое затухание (50%)
    # 0.1 = более резкое затухание (10%)
```

### Альтернативные стратегии

**Экспоненциальное затухание:**
```python
def calculate_position_weights_exp(tokens: List[str], decay: float = 0.5):
    weights = {}
    for position, token in enumerate(tokens):
        weight = decay ** (position / 5)  # резкое падение
        weights[token] = weight
    return weights
```

**Ступенчатое взвешивание:**
```python
def calculate_position_weights_steps(tokens: List[str]):
    weights = {}
    for position, token in enumerate(tokens):
        if position < 3:
            weight = 1.0  # первые 3 = главные
        elif position < 7:
            weight = 0.6  # средние
        else:
            weight = 0.3  # остальные
        weights[token] = weight
    return weights
```

## Тестирование

✅ Синтаксис проверен
✅ Все файлы скомпилированы успешно
✅ Обратная совместимость сохранена

### Рекомендации по тестированию

1. Выберите несколько каналов с известной тематикой
2. Запустите `diagnose_similarity.py` до и после пересчета
3. Сравните топ-10 похожих каналов
4. Проверьте, что главные темы совпадают чаще

## FAQ

**Q: Нужно ли переанализировать все каналы?**
A: Нет, keywords остаются прежними. Нужно только пересчитать similarity.

**Q: Как быстро пересчитать similarity?**
A: Batch для всех: 10-60 мин. Single channel: 10-30 сек.

**Q: Можно ли откатить изменения?**
A: Да, просто откатите изменения в git и пересчитайте similarity.

**Q: Совместимо ли с semantic search?**
A: Да, взвешивание можно использовать и для embeddings.

**Q: Как понять, что изменения работают?**
A: Запустите `diagnose_similarity.py` и проверьте топ-10 каналов. Каналы с совпадением по главным ключам должны быть выше.
